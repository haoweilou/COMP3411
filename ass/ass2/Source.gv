digraph Tree {
node [shape=box, style="filled, rounded", color="black", fontname=helvetica] ;
edge [fontname=helvetica] ;
0 [label=<X<SUB>7</SUB> &le; 0.5<br/>entropy = 0.796<br/>samples = 32561<br/>value = [24720, 7841]>, fillcolor="#eda978"] ;
1 [label=<X<SUB>4</SUB> &le; 12.5<br/>entropy = 0.992<br/>samples = 13193<br/>value = [7275, 5918]>, fillcolor="#fae7da"] ;
0 -> 1 [labeldistance=2.5, labelangle=45, headlabel="True"] ;
2 [label=<X<SUB>10</SUB> &le; 5095.5<br/>entropy = 0.915<br/>samples = 9224<br/>value = [6178, 3046]>, fillcolor="#f2bf9b"] ;
1 -> 2 ;
3 [label=<X<SUB>4</SUB> &le; 8.5<br/>entropy = 0.877<br/>samples = 8766<br/>value = [6170, 2596]>, fillcolor="#f0b68c"] ;
2 -> 3 ;
4 [label=<X<SUB>11</SUB> &le; 1791.5<br/>entropy = 0.48<br/>samples = 1459<br/>value = [1308, 151]>, fillcolor="#e89050"] ;
3 -> 4 ;
5 [label=<X<SUB>0</SUB> &le; 36.5<br/>entropy = 0.456<br/>samples = 1428<br/>value = [1291, 137]>, fillcolor="#e88e4e"] ;
4 -> 5 ;
6 [label=<X<SUB>12</SUB> &le; 49.0<br/>entropy = 0.255<br/>samples = 398<br/>value = [381, 17]>, fillcolor="#e68742"] ;
5 -> 6 ;
7 [label=<X<SUB>2</SUB> &le; 180784.0<br/>entropy = 0.196<br/>samples = 329<br/>value = [319, 10]>, fillcolor="#e6853f"] ;
6 -> 7 ;
8 [label=<entropy = 0.311<br/>samples = 125<br/>value = [118, 7]>, fillcolor="#e78845"] ;
7 -> 8 ;
9 [label=<entropy = 0.111<br/>samples = 204<br/>value = [201, 3]>, fillcolor="#e5833c"] ;
7 -> 9 ;
10 [label=<X<SUB>3</SUB> &le; 4.5<br/>entropy = 0.474<br/>samples = 69<br/>value = [62, 7]>, fillcolor="#e88f4f"] ;
6 -> 10 ;
11 [label=<entropy = 0.556<br/>samples = 54<br/>value = [47, 7]>, fillcolor="#e99456"] ;
10 -> 11 ;
12 [label=<entropy = 0.0<br/>samples = 15<br/>value = [15, 0]>, fillcolor="#e58139"] ;
10 -> 12 ;
13 [label=<X<SUB>0</SUB> &le; 66.5<br/>entropy = 0.519<br/>samples = 1030<br/>value = [910, 120]>, fillcolor="#e89253"] ;
5 -> 13 ;
14 [label=<X<SUB>3</SUB> &le; 2.5<br/>entropy = 0.558<br/>samples = 914<br/>value = [795, 119]>, fillcolor="#e99457"] ;
13 -> 14 ;
15 [label=<entropy = 0.663<br/>samples = 418<br/>value = [346, 72]>, fillcolor="#ea9b62"] ;
14 -> 15 ;
16 [label=<entropy = 0.452<br/>samples = 496<br/>value = [449, 47]>, fillcolor="#e88e4e"] ;
14 -> 16 ;
17 [label=<X<SUB>2</SUB> &le; 28057.0<br/>entropy = 0.072<br/>samples = 116<br/>value = [115, 1]>, fillcolor="#e5823b"] ;
13 -> 17 ;
18 [label=<entropy = 0.0<br/>samples = 1<br/>value = [0, 1]>, fillcolor="#399de5"] ;
17 -> 18 ;
19 [label=<entropy = 0.0<br/>samples = 115<br/>value = [115, 0]>, fillcolor="#e58139"] ;
17 -> 19 ;
20 [label=<X<SUB>11</SUB> &le; 1989.5<br/>entropy = 0.993<br/>samples = 31<br/>value = [17, 14]>, fillcolor="#fae9dc"] ;
4 -> 20 ;
21 [label=<entropy = 0.544<br/>samples = 16<br/>value = [2, 14]>, fillcolor="#55abe9"] ;
20 -> 21 ;
22 [label=<entropy = 0.0<br/>samples = 15<br/>value = [15, 0]>, fillcolor="#e58139"] ;
20 -> 22 ;
23 [label=<X<SUB>0</SUB> &le; 35.5<br/>entropy = 0.92<br/>samples = 7307<br/>value = [4862, 2445]>, fillcolor="#f2c09d"] ;
3 -> 23 ;
24 [label=<X<SUB>0</SUB> &le; 27.5<br/>entropy = 0.744<br/>samples = 2336<br/>value = [1842, 494]>, fillcolor="#eca36e"] ;
23 -> 24 ;
25 [label=<X<SUB>0</SUB> &le; 23.5<br/>entropy = 0.513<br/>samples = 621<br/>value = [550, 71]>, fillcolor="#e89153"] ;
24 -> 25 ;
26 [label=<X<SUB>6</SUB> &le; 13.5<br/>entropy = 0.21<br/>samples = 151<br/>value = [146, 5]>, fillcolor="#e68540"] ;
25 -> 26 ;
27 [label=<entropy = 0.107<br/>samples = 142<br/>value = [140, 2]>, fillcolor="#e5833c"] ;
26 -> 27 ;
28 [label=<entropy = 0.918<br/>samples = 9<br/>value = [6, 3]>, fillcolor="#f2c09c"] ;
26 -> 28 ;
29 [label=<X<SUB>12</SUB> &le; 35.5<br/>entropy = 0.585<br/>samples = 470<br/>value = [404, 66]>, fillcolor="#e99659"] ;
25 -> 29 ;
30 [label=<entropy = 0.0<br/>samples = 27<br/>value = [27, 0]>, fillcolor="#e58139"] ;
29 -> 30 ;
31 [label=<entropy = 0.607<br/>samples = 443<br/>value = [377, 66]>, fillcolor="#ea975c"] ;
29 -> 31 ;
32 [label=<X<SUB>11</SUB> &le; 1794.0<br/>entropy = 0.806<br/>samples = 1715<br/>value = [1292, 423]>, fillcolor="#eeaa7a"] ;
24 -> 32 ;
33 [label=<X<SUB>4</SUB> &le; 9.5<br/>entropy = 0.784<br/>samples = 1663<br/>value = [1275, 388]>, fillcolor="#eda775"] ;
32 -> 33 ;
34 [label=<entropy = 0.688<br/>samples = 936<br/>value = [764, 172]>, fillcolor="#eb9d66"] ;
33 -> 34 ;
35 [label=<entropy = 0.878<br/>samples = 727<br/>value = [511, 216]>, fillcolor="#f0b68d"] ;
33 -> 35 ;
36 [label=<X<SUB>11</SUB> &le; 1989.5<br/>entropy = 0.912<br/>samples = 52<br/>value = [17, 35]>, fillcolor="#99cdf2"] ;
32 -> 36 ;
37 [label=<entropy = 0.183<br/>samples = 36<br/>value = [1, 35]>, fillcolor="#3fa0e6"] ;
36 -> 37 ;
38 [label=<entropy = 0.0<br/>samples = 16<br/>value = [16, 0]>, fillcolor="#e58139"] ;
36 -> 38 ;
39 [label=<X<SUB>12</SUB> &le; 34.5<br/>entropy = 0.966<br/>samples = 4971<br/>value = [3020, 1951]>, fillcolor="#f6d2b9"] ;
23 -> 39 ;
40 [label=<X<SUB>4</SUB> &le; 9.5<br/>entropy = 0.517<br/>samples = 440<br/>value = [389, 51]>, fillcolor="#e89253"] ;
39 -> 40 ;
41 [label=<X<SUB>6</SUB> &le; 10.5<br/>entropy = 0.351<br/>samples = 273<br/>value = [255, 18]>, fillcolor="#e78a47"] ;
40 -> 41 ;
42 [label=<entropy = 0.232<br/>samples = 212<br/>value = [204, 8]>, fillcolor="#e68641"] ;
41 -> 42 ;
43 [label=<entropy = 0.644<br/>samples = 61<br/>value = [51, 10]>, fillcolor="#ea9a60"] ;
41 -> 43 ;
44 [label=<X<SUB>11</SUB> &le; 1580.0<br/>entropy = 0.717<br/>samples = 167<br/>value = [134, 33]>, fillcolor="#eba06a"] ;
40 -> 44 ;
45 [label=<entropy = 0.675<br/>samples = 163<br/>value = [134, 29]>, fillcolor="#eb9c64"] ;
44 -> 45 ;
46 [label=<entropy = 0.0<br/>samples = 4<br/>value = [0, 4]>, fillcolor="#399de5"] ;
44 -> 46 ;
47 [label=<X<SUB>11</SUB> &le; 1782.5<br/>entropy = 0.981<br/>samples = 4531<br/>value = [2631, 1900]>, fillcolor="#f8dcc8"] ;
39 -> 47 ;
48 [label=<X<SUB>4</SUB> &le; 9.5<br/>entropy = 0.971<br/>samples = 4308<br/>value = [2588, 1720]>, fillcolor="#f6d5bd"] ;
47 -> 48 ;
49 [label=<entropy = 0.93<br/>samples = 2401<br/>value = [1572, 829]>, fillcolor="#f3c3a1"] ;
48 -> 49 ;
50 [label=<entropy = 0.997<br/>samples = 1907<br/>value = [1016, 891]>, fillcolor="#fcefe7"] ;
48 -> 50 ;
51 [label=<X<SUB>11</SUB> &le; 1989.5<br/>entropy = 0.707<br/>samples = 223<br/>value = [43, 180]>, fillcolor="#68b4eb"] ;
47 -> 51 ;
52 [label=<entropy = 0.218<br/>samples = 172<br/>value = [6, 166]>, fillcolor="#40a1e6"] ;
51 -> 52 ;
53 [label=<entropy = 0.848<br/>samples = 51<br/>value = [37, 14]>, fillcolor="#efb184"] ;
51 -> 53 ;
54 [label=<X<SUB>0</SUB> &le; 61.5<br/>entropy = 0.127<br/>samples = 458<br/>value = [8, 450]>, fillcolor="#3d9fe5"] ;
2 -> 54 ;
55 [label=<entropy = 0.0<br/>samples = 410<br/>value = [0, 410]>, fillcolor="#399de5"] ;
54 -> 55 ;
56 [label=<X<SUB>10</SUB> &le; 10585.5<br/>entropy = 0.65<br/>samples = 48<br/>value = [8, 40]>, fillcolor="#61b1ea"] ;
54 -> 56 ;
57 [label=<X<SUB>10</SUB> &le; 9976.0<br/>entropy = 0.764<br/>samples = 36<br/>value = [8, 28]>, fillcolor="#72b9ec"] ;
56 -> 57 ;
58 [label=<X<SUB>10</SUB> &le; 7032.5<br/>entropy = 0.544<br/>samples = 32<br/>value = [4, 28]>, fillcolor="#55abe9"] ;
57 -> 58 ;
59 [label=<entropy = 0.863<br/>samples = 14<br/>value = [4, 10]>, fillcolor="#88c4ef"] ;
58 -> 59 ;
60 [label=<entropy = 0.0<br/>samples = 18<br/>value = [0, 18]>, fillcolor="#399de5"] ;
58 -> 60 ;
61 [label=<entropy = 0.0<br/>samples = 4<br/>value = [4, 0]>, fillcolor="#e58139"] ;
57 -> 61 ;
62 [label=<entropy = 0.0<br/>samples = 12<br/>value = [0, 12]>, fillcolor="#399de5"] ;
56 -> 62 ;
63 [label=<X<SUB>10</SUB> &le; 5095.5<br/>entropy = 0.85<br/>samples = 3969<br/>value = [1097, 2872]>, fillcolor="#85c2ef"] ;
1 -> 63 ;
64 [label=<X<SUB>11</SUB> &le; 1782.5<br/>entropy = 0.911<br/>samples = 3356<br/>value = [1094, 2262]>, fillcolor="#99ccf2"] ;
63 -> 64 ;
65 [label=<X<SUB>12</SUB> &le; 31.0<br/>entropy = 0.944<br/>samples = 2999<br/>value = [1083, 1916]>, fillcolor="#a9d4f4"] ;
64 -> 65 ;
66 [label=<X<SUB>0</SUB> &le; 29.5<br/>entropy = 0.874<br/>samples = 228<br/>value = [161, 67]>, fillcolor="#f0b58b"] ;
65 -> 66 ;
67 [label=<entropy = 0.0<br/>samples = 22<br/>value = [22, 0]>, fillcolor="#e58139"] ;
66 -> 67 ;
68 [label=<X<SUB>4</SUB> &le; 14.5<br/>entropy = 0.91<br/>samples = 206<br/>value = [139, 67]>, fillcolor="#f2be98"] ;
66 -> 68 ;
69 [label=<X<SUB>0</SUB> &le; 67.5<br/>entropy = 0.846<br/>samples = 161<br/>value = [117, 44]>, fillcolor="#efb083"] ;
68 -> 69 ;
70 [label=<entropy = 0.904<br/>samples = 122<br/>value = [83, 39]>, fillcolor="#f1bc96"] ;
69 -> 70 ;
71 [label=<entropy = 0.552<br/>samples = 39<br/>value = [34, 5]>, fillcolor="#e99456"] ;
69 -> 71 ;
72 [label=<X<SUB>12</SUB> &le; 23.5<br/>entropy = 1.0<br/>samples = 45<br/>value = [22, 23]>, fillcolor="#f6fbfe"] ;
68 -> 72 ;
73 [label=<entropy = 0.961<br/>samples = 26<br/>value = [16, 10]>, fillcolor="#f5d0b5"] ;
72 -> 73 ;
74 [label=<entropy = 0.9<br/>samples = 19<br/>value = [6, 13]>, fillcolor="#94caf1"] ;
72 -> 74 ;
75 [label=<X<SUB>0</SUB> &le; 28.5<br/>entropy = 0.918<br/>samples = 2771<br/>value = [922, 1849]>, fillcolor="#9ccef2"] ;
65 -> 75 ;
76 [label=<X<SUB>0</SUB> &le; 23.5<br/>entropy = 0.969<br/>samples = 159<br/>value = [96, 63]>, fillcolor="#f6d4bb"] ;
75 -> 76 ;
77 [label=<entropy = 0.0<br/>samples = 5<br/>value = [5, 0]>, fillcolor="#e58139"] ;
76 -> 77 ;
78 [label=<X<SUB>2</SUB> &le; 108785.0<br/>entropy = 0.976<br/>samples = 154<br/>value = [91, 63]>, fillcolor="#f7d8c2"] ;
76 -> 78 ;
79 [label=<entropy = 0.831<br/>samples = 38<br/>value = [28, 10]>, fillcolor="#eeae80"] ;
78 -> 79 ;
80 [label=<entropy = 0.995<br/>samples = 116<br/>value = [63, 53]>, fillcolor="#fbebe0"] ;
78 -> 80 ;
81 [label=<X<SUB>10</SUB> &le; 3120.0<br/>entropy = 0.9<br/>samples = 2612<br/>value = [826, 1786]>, fillcolor="#95caf1"] ;
75 -> 81 ;
82 [label=<X<SUB>6</SUB> &le; 3.5<br/>entropy = 0.891<br/>samples = 2566<br/>value = [790, 1776]>, fillcolor="#91c9f1"] ;
81 -> 82 ;
83 [label=<entropy = 0.996<br/>samples = 280<br/>value = [130, 150]>, fillcolor="#e5f2fc"] ;
82 -> 83 ;
84 [label=<entropy = 0.867<br/>samples = 2286<br/>value = [660, 1626]>, fillcolor="#89c5f0"] ;
82 -> 84 ;
85 [label=<X<SUB>10</SUB> &le; 4225.0<br/>entropy = 0.755<br/>samples = 46<br/>value = [36, 10]>, fillcolor="#eca470"] ;
81 -> 85 ;
86 [label=<entropy = 0.0<br/>samples = 18<br/>value = [18, 0]>, fillcolor="#e58139"] ;
85 -> 86 ;
87 [label=<entropy = 0.94<br/>samples = 28<br/>value = [18, 10]>, fillcolor="#f3c7a7"] ;
85 -> 87 ;
88 [label=<X<SUB>11</SUB> &le; 1989.5<br/>entropy = 0.198<br/>samples = 357<br/>value = [11, 346]>, fillcolor="#3fa0e6"] ;
64 -> 88 ;
89 [label=<X<SUB>1</SUB> &le; 1.5<br/>entropy = 0.033<br/>samples = 290<br/>value = [1, 289]>, fillcolor="#3a9de5"] ;
88 -> 89 ;
90 [label=<entropy = 0.371<br/>samples = 14<br/>value = [1, 13]>, fillcolor="#48a5e7"] ;
89 -> 90 ;
91 [label=<entropy = 0.0<br/>samples = 276<br/>value = [0, 276]>, fillcolor="#399de5"] ;
89 -> 91 ;
92 [label=<X<SUB>11</SUB> &le; 2168.5<br/>entropy = 0.608<br/>samples = 67<br/>value = [10, 57]>, fillcolor="#5caeea"] ;
88 -> 92 ;
93 [label=<entropy = 0.0<br/>samples = 9<br/>value = [9, 0]>, fillcolor="#e58139"] ;
92 -> 93 ;
94 [label=<X<SUB>11</SUB> &le; 2212.5<br/>entropy = 0.126<br/>samples = 58<br/>value = [1, 57]>, fillcolor="#3c9fe5"] ;
92 -> 94 ;
95 [label=<entropy = 0.918<br/>samples = 3<br/>value = [1, 2]>, fillcolor="#9ccef2"] ;
94 -> 95 ;
96 [label=<entropy = 0.0<br/>samples = 55<br/>value = [0, 55]>, fillcolor="#399de5"] ;
94 -> 96 ;
97 [label=<X<SUB>0</SUB> &le; 62.5<br/>entropy = 0.045<br/>samples = 613<br/>value = [3, 610]>, fillcolor="#3a9de5"] ;
63 -> 97 ;
98 [label=<entropy = 0.0<br/>samples = 542<br/>value = [0, 542]>, fillcolor="#399de5"] ;
97 -> 98 ;
99 [label=<X<SUB>1</SUB> &le; 5.5<br/>entropy = 0.253<br/>samples = 71<br/>value = [3, 68]>, fillcolor="#42a1e6"] ;
97 -> 99 ;
100 [label=<X<SUB>10</SUB> &le; 7227.5<br/>entropy = 0.127<br/>samples = 57<br/>value = [1, 56]>, fillcolor="#3d9fe5"] ;
99 -> 100 ;
101 [label=<entropy = 0.503<br/>samples = 9<br/>value = [1, 8]>, fillcolor="#52a9e8"] ;
100 -> 101 ;
102 [label=<entropy = 0.0<br/>samples = 48<br/>value = [0, 48]>, fillcolor="#399de5"] ;
100 -> 102 ;
103 [label=<entropy = 0.592<br/>samples = 14<br/>value = [2, 12]>, fillcolor="#5aade9"] ;
99 -> 103 ;
104 [label=<X<SUB>10</SUB> &le; 7073.5<br/>entropy = 0.467<br/>samples = 19368<br/>value = [17445, 1923]>, fillcolor="#e88f4f"] ;
0 -> 104 [labeldistance=2.5, labelangle=-45, headlabel="False"] ;
105 [label=<X<SUB>7</SUB> &le; 4.5<br/>entropy = 0.4<br/>samples = 18932<br/>value = [17431, 1501]>, fillcolor="#e78c4a"] ;
104 -> 105 ;
106 [label=<X<SUB>4</SUB> &le; 12.5<br/>entropy = 0.286<br/>samples = 17482<br/>value = [16610, 872]>, fillcolor="#e68843"] ;
105 -> 106 ;
107 [label=<X<SUB>0</SUB> &le; 28.5<br/>entropy = 0.172<br/>samples = 14036<br/>value = [13677, 359]>, fillcolor="#e6843e"] ;
106 -> 107 ;
108 [label=<X<SUB>12</SUB> &le; 44.5<br/>entropy = 0.046<br/>samples = 6296<br/>value = [6264, 32]>, fillcolor="#e5823a"] ;
107 -> 108 ;
109 [label=<X<SUB>11</SUB> &le; 2218.0<br/>entropy = 0.025<br/>samples = 5553<br/>value = [5539, 14]>, fillcolor="#e5813a"] ;
108 -> 109 ;
110 [label=<X<SUB>2</SUB> &le; 23840.0<br/>entropy = 0.021<br/>samples = 5547<br/>value = [5536, 11]>, fillcolor="#e58139"] ;
109 -> 110 ;
111 [label=<entropy = 0.454<br/>samples = 21<br/>value = [19, 2]>, fillcolor="#e88e4e"] ;
110 -> 111 ;
112 [label=<entropy = 0.017<br/>samples = 5526<br/>value = [5517, 9]>, fillcolor="#e58139"] ;
110 -> 112 ;
113 [label=<entropy = 1.0<br/>samples = 6<br/>value = [3, 3]>, fillcolor="#ffffff"] ;
109 -> 113 ;
114 [label=<X<SUB>0</SUB> &le; 23.5<br/>entropy = 0.165<br/>samples = 743<br/>value = [725, 18]>, fillcolor="#e6843e"] ;
108 -> 114 ;
115 [label=<X<SUB>3</SUB> &le; 5.5<br/>entropy = 0.052<br/>samples = 343<br/>value = [341, 2]>, fillcolor="#e5823a"] ;
114 -> 115 ;
116 [label=<entropy = 0.232<br/>samples = 53<br/>value = [51, 2]>, fillcolor="#e68641"] ;
115 -> 116 ;
117 [label=<entropy = 0.0<br/>samples = 290<br/>value = [290, 0]>, fillcolor="#e58139"] ;
115 -> 117 ;
118 [label=<X<SUB>2</SUB> &le; 213025.5<br/>entropy = 0.242<br/>samples = 400<br/>value = [384, 16]>, fillcolor="#e68641"] ;
114 -> 118 ;
119 [label=<entropy = 0.31<br/>samples = 270<br/>value = [255, 15]>, fillcolor="#e78845"] ;
118 -> 119 ;
120 [label=<entropy = 0.065<br/>samples = 130<br/>value = [129, 1]>, fillcolor="#e5823b"] ;
118 -> 120 ;
121 [label=<X<SUB>12</SUB> &le; 40.5<br/>entropy = 0.253<br/>samples = 7740<br/>value = [7413, 327]>, fillcolor="#e68742"] ;
107 -> 121 ;
122 [label=<X<SUB>11</SUB> &le; 2218.5<br/>entropy = 0.176<br/>samples = 6036<br/>value = [5877, 159]>, fillcolor="#e6843e"] ;
121 -> 122 ;
123 [label=<X<SUB>6</SUB> &le; 9.5<br/>entropy = 0.168<br/>samples = 6008<br/>value = [5859, 149]>, fillcolor="#e6843e"] ;
122 -> 123 ;
124 [label=<entropy = 0.132<br/>samples = 4757<br/>value = [4670, 87]>, fillcolor="#e5833d"] ;
123 -> 124 ;
125 [label=<entropy = 0.285<br/>samples = 1251<br/>value = [1189, 62]>, fillcolor="#e68843"] ;
123 -> 125 ;
126 [label=<entropy = 0.94<br/>samples = 28<br/>value = [18, 10]>, fillcolor="#f3c7a7"] ;
122 -> 126 ;
127 [label=<X<SUB>11</SUB> &le; 2391.5<br/>entropy = 0.465<br/>samples = 1704<br/>value = [1536, 168]>, fillcolor="#e88f4f"] ;
121 -> 127 ;
128 [label=<X<SUB>9</SUB> &le; 0.5<br/>entropy = 0.446<br/>samples = 1691<br/>value = [1534, 157]>, fillcolor="#e88e4d"] ;
127 -> 128 ;
129 [label=<entropy = 0.302<br/>samples = 652<br/>value = [617, 35]>, fillcolor="#e68844"] ;
128 -> 129 ;
130 [label=<entropy = 0.522<br/>samples = 1039<br/>value = [917, 122]>, fillcolor="#e89253"] ;
128 -> 130 ;
131 [label=<entropy = 0.619<br/>samples = 13<br/>value = [2, 11]>, fillcolor="#5dafea"] ;
127 -> 131 ;
132 [label=<X<SUB>0</SUB> &le; 27.5<br/>entropy = 0.607<br/>samples = 3446<br/>value = [2933, 513]>, fillcolor="#ea975c"] ;
106 -> 132 ;
133 [label=<X<SUB>11</SUB> &le; 2102.5<br/>entropy = 0.134<br/>samples = 1013<br/>value = [994, 19]>, fillcolor="#e5833d"] ;
132 -> 133 ;
134 [label=<X<SUB>12</SUB> &le; 53.5<br/>entropy = 0.118<br/>samples = 1008<br/>value = [992, 16]>, fillcolor="#e5833c"] ;
133 -> 134 ;
135 [label=<X<SUB>12</SUB> &le; 39.5<br/>entropy = 0.085<br/>samples = 943<br/>value = [933, 10]>, fillcolor="#e5823b"] ;
134 -> 135 ;
136 [label=<entropy = 0.0<br/>samples = 299<br/>value = [299, 0]>, fillcolor="#e58139"] ;
135 -> 136 ;
137 [label=<entropy = 0.116<br/>samples = 644<br/>value = [634, 10]>, fillcolor="#e5833c"] ;
135 -> 137 ;
138 [label=<X<SUB>0</SUB> &le; 24.5<br/>entropy = 0.444<br/>samples = 65<br/>value = [59, 6]>, fillcolor="#e88e4d"] ;
134 -> 138 ;
139 [label=<entropy = 0.0<br/>samples = 27<br/>value = [27, 0]>, fillcolor="#e58139"] ;
138 -> 139 ;
140 [label=<entropy = 0.629<br/>samples = 38<br/>value = [32, 6]>, fillcolor="#ea995e"] ;
138 -> 140 ;
141 [label=<entropy = 0.971<br/>samples = 5<br/>value = [2, 3]>, fillcolor="#bddef6"] ;
133 -> 141 ;
142 [label=<X<SUB>12</SUB> &le; 43.5<br/>entropy = 0.728<br/>samples = 2433<br/>value = [1939, 494]>, fillcolor="#eca16b"] ;
132 -> 142 ;
143 [label=<X<SUB>11</SUB> &le; 2365.5<br/>entropy = 0.557<br/>samples = 1525<br/>value = [1327, 198]>, fillcolor="#e99457"] ;
142 -> 143 ;
144 [label=<X<SUB>4</SUB> &le; 14.5<br/>entropy = 0.541<br/>samples = 1515<br/>value = [1327, 188]>, fillcolor="#e99355"] ;
143 -> 144 ;
145 [label=<entropy = 0.495<br/>samples = 1404<br/>value = [1252, 152]>, fillcolor="#e89051"] ;
144 -> 145 ;
146 [label=<entropy = 0.909<br/>samples = 111<br/>value = [75, 36]>, fillcolor="#f1bd98"] ;
144 -> 146 ;
147 [label=<entropy = 0.0<br/>samples = 10<br/>value = [0, 10]>, fillcolor="#399de5"] ;
143 -> 147 ;
148 [label=<X<SUB>11</SUB> &le; 2391.5<br/>entropy = 0.911<br/>samples = 908<br/>value = [612, 296]>, fillcolor="#f2be99"] ;
142 -> 148 ;
149 [label=<X<SUB>4</SUB> &le; 14.5<br/>entropy = 0.898<br/>samples = 893<br/>value = [612, 281]>, fillcolor="#f1bb94"] ;
148 -> 149 ;
150 [label=<entropy = 0.865<br/>samples = 780<br/>value = [556, 224]>, fillcolor="#efb489"] ;
149 -> 150 ;
151 [label=<entropy = 1.0<br/>samples = 113<br/>value = [56, 57]>, fillcolor="#fcfdff"] ;
149 -> 151 ;
152 [label=<entropy = 0.0<br/>samples = 15<br/>value = [0, 15]>, fillcolor="#399de5"] ;
148 -> 152 ;
153 [label=<X<SUB>4</SUB> &le; 10.5<br/>entropy = 0.987<br/>samples = 1450<br/>value = [821, 629]>, fillcolor="#f9e2d1"] ;
105 -> 153 ;
154 [label=<X<SUB>4</SUB> &le; 8.5<br/>entropy = 0.895<br/>samples = 902<br/>value = [621, 281]>, fillcolor="#f1ba93"] ;
153 -> 154 ;
155 [label=<X<SUB>2</SUB> &le; 183483.0<br/>entropy = 0.471<br/>samples = 139<br/>value = [125, 14]>, fillcolor="#e88f4f"] ;
154 -> 155 ;
156 [label=<X<SUB>0</SUB> &le; 31.5<br/>entropy = 0.645<br/>samples = 79<br/>value = [66, 13]>, fillcolor="#ea9a60"] ;
155 -> 156 ;
157 [label=<entropy = 0.0<br/>samples = 24<br/>value = [24, 0]>, fillcolor="#e58139"] ;
156 -> 157 ;
158 [label=<X<SUB>2</SUB> &le; 73602.5<br/>entropy = 0.789<br/>samples = 55<br/>value = [42, 13]>, fillcolor="#eda876"] ;
156 -> 158 ;
159 [label=<entropy = 0.0<br/>samples = 10<br/>value = [10, 0]>, fillcolor="#e58139"] ;
158 -> 159 ;
160 [label=<entropy = 0.867<br/>samples = 45<br/>value = [32, 13]>, fillcolor="#f0b489"] ;
158 -> 160 ;
161 [label=<X<SUB>1</SUB> &le; 6.5<br/>entropy = 0.122<br/>samples = 60<br/>value = [59, 1]>, fillcolor="#e5833c"] ;
155 -> 161 ;
162 [label=<entropy = 0.0<br/>samples = 58<br/>value = [58, 0]>, fillcolor="#e58139"] ;
161 -> 162 ;
163 [label=<entropy = 1.0<br/>samples = 2<br/>value = [1, 1]>, fillcolor="#ffffff"] ;
161 -> 163 ;
164 [label=<X<SUB>0</SUB> &le; 26.5<br/>entropy = 0.934<br/>samples = 763<br/>value = [496, 267]>, fillcolor="#f3c5a4"] ;
154 -> 164 ;
165 [label=<X<SUB>12</SUB> &le; 38.0<br/>entropy = 0.524<br/>samples = 93<br/>value = [82, 11]>, fillcolor="#e89254"] ;
164 -> 165 ;
166 [label=<entropy = 0.0<br/>samples = 29<br/>value = [29, 0]>, fillcolor="#e58139"] ;
165 -> 166 ;
167 [label=<X<SUB>2</SUB> &le; 228268.0<br/>entropy = 0.662<br/>samples = 64<br/>value = [53, 11]>, fillcolor="#ea9b62"] ;
165 -> 167 ;
168 [label=<entropy = 0.446<br/>samples = 43<br/>value = [39, 4]>, fillcolor="#e88e4d"] ;
167 -> 168 ;
169 [label=<entropy = 0.918<br/>samples = 21<br/>value = [14, 7]>, fillcolor="#f2c09c"] ;
167 -> 169 ;
170 [label=<X<SUB>6</SUB> &le; 4.5<br/>entropy = 0.96<br/>samples = 670<br/>value = [414, 256]>, fillcolor="#f5cfb3"] ;
164 -> 170 ;
171 [label=<X<SUB>10</SUB> &le; 4225.0<br/>entropy = 0.999<br/>samples = 357<br/>value = [186, 171]>, fillcolor="#fdf5ef"] ;
170 -> 171 ;
172 [label=<entropy = 0.997<br/>samples = 350<br/>value = [186, 164]>, fillcolor="#fcf0e8"] ;
171 -> 172 ;
173 [label=<entropy = 0.0<br/>samples = 7<br/>value = [0, 7]>, fillcolor="#399de5"] ;
171 -> 173 ;
174 [label=<X<SUB>6</SUB> &le; 9.5<br/>entropy = 0.844<br/>samples = 313<br/>value = [228, 85]>, fillcolor="#efb083"] ;
170 -> 174 ;
175 [label=<entropy = 0.678<br/>samples = 162<br/>value = [133, 29]>, fillcolor="#eb9c64"] ;
174 -> 175 ;
176 [label=<entropy = 0.951<br/>samples = 151<br/>value = [95, 56]>, fillcolor="#f4cbae"] ;
174 -> 176 ;
177 [label=<X<SUB>11</SUB> &le; 1794.0<br/>entropy = 0.947<br/>samples = 548<br/>value = [200, 348]>, fillcolor="#abd5f4"] ;
153 -> 177 ;
178 [label=<X<SUB>6</SUB> &le; 3.5<br/>entropy = 0.969<br/>samples = 500<br/>value = [198, 302]>, fillcolor="#bbddf6"] ;
177 -> 178 ;
179 [label=<X<SUB>10</SUB> &le; 1442.5<br/>entropy = 0.988<br/>samples = 124<br/>value = [70, 54]>, fillcolor="#f9e2d2"] ;
178 -> 179 ;
180 [label=<X<SUB>0</SUB> &le; 33.5<br/>entropy = 0.994<br/>samples = 119<br/>value = [65, 54]>, fillcolor="#fbeadd"] ;
179 -> 180 ;
181 [label=<entropy = 0.912<br/>samples = 55<br/>value = [37, 18]>, fillcolor="#f2be99"] ;
180 -> 181 ;
182 [label=<entropy = 0.989<br/>samples = 64<br/>value = [28, 36]>, fillcolor="#d3e9f9"] ;
180 -> 182 ;
183 [label=<entropy = 0.0<br/>samples = 5<br/>value = [5, 0]>, fillcolor="#e58139"] ;
179 -> 183 ;
184 [label=<X<SUB>0</SUB> &le; 25.5<br/>entropy = 0.925<br/>samples = 376<br/>value = [128, 248]>, fillcolor="#9fd0f2"] ;
178 -> 184 ;
185 [label=<entropy = 0.811<br/>samples = 20<br/>value = [15, 5]>, fillcolor="#eeab7b"] ;
184 -> 185 ;
186 [label=<X<SUB>12</SUB> &le; 72.5<br/>entropy = 0.902<br/>samples = 356<br/>value = [113, 243]>, fillcolor="#95cbf1"] ;
184 -> 186 ;
187 [label=<entropy = 0.893<br/>samples = 352<br/>value = [109, 243]>, fillcolor="#92c9f1"] ;
186 -> 187 ;
188 [label=<entropy = 0.0<br/>samples = 4<br/>value = [4, 0]>, fillcolor="#e58139"] ;
186 -> 188 ;
189 [label=<X<SUB>1</SUB> &le; 3.0<br/>entropy = 0.25<br/>samples = 48<br/>value = [2, 46]>, fillcolor="#42a1e6"] ;
177 -> 189 ;
190 [label=<entropy = 0.65<br/>samples = 12<br/>value = [2, 10]>, fillcolor="#61b1ea"] ;
189 -> 190 ;
191 [label=<entropy = 0.0<br/>samples = 36<br/>value = [0, 36]>, fillcolor="#399de5"] ;
189 -> 191 ;
192 [label=<X<SUB>4</SUB> &le; 10.5<br/>entropy = 0.205<br/>samples = 436<br/>value = [14, 422]>, fillcolor="#40a0e6"] ;
104 -> 192 ;
193 [label=<X<SUB>0</SUB> &le; 20.5<br/>entropy = 0.454<br/>samples = 147<br/>value = [14, 133]>, fillcolor="#4ea7e8"] ;
192 -> 193 ;
194 [label=<entropy = 0.722<br/>samples = 5<br/>value = [4, 1]>, fillcolor="#eca06a"] ;
193 -> 194 ;
195 [label=<X<SUB>2</SUB> &le; 33379.0<br/>entropy = 0.367<br/>samples = 142<br/>value = [10, 132]>, fillcolor="#48a4e7"] ;
193 -> 195 ;
196 [label=<entropy = 0.971<br/>samples = 5<br/>value = [3, 2]>, fillcolor="#f6d5bd"] ;
195 -> 196 ;
197 [label=<X<SUB>12</SUB> &le; 35.5<br/>entropy = 0.291<br/>samples = 137<br/>value = [7, 130]>, fillcolor="#44a2e6"] ;
195 -> 197 ;
198 [label=<entropy = 0.691<br/>samples = 27<br/>value = [5, 22]>, fillcolor="#66b3eb"] ;
197 -> 198 ;
199 [label=<X<SUB>5</SUB> &le; 1.0<br/>entropy = 0.131<br/>samples = 110<br/>value = [2, 108]>, fillcolor="#3d9fe5"] ;
197 -> 199 ;
200 [label=<X<SUB>10</SUB> &le; 7669.5<br/>entropy = 0.33<br/>samples = 33<br/>value = [2, 31]>, fillcolor="#46a3e7"] ;
199 -> 200 ;
201 [label=<entropy = 1.0<br/>samples = 2<br/>value = [1, 1]>, fillcolor="#ffffff"] ;
200 -> 201 ;
202 [label=<entropy = 0.206<br/>samples = 31<br/>value = [1, 30]>, fillcolor="#40a0e6"] ;
200 -> 202 ;
203 [label=<entropy = 0.0<br/>samples = 77<br/>value = [0, 77]>, fillcolor="#399de5"] ;
199 -> 203 ;
204 [label=<entropy = 0.0<br/>samples = 289<br/>value = [0, 289]>, fillcolor="#399de5"] ;
192 -> 204 ;
}
